{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql.functions import udf, col,concat_ws, from_unixtime, substring, monotonically_increasing_id,split, col,array, lit, explode, from_json, json_tuple, length, to_timestamp  \n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format,from_unixtime\n",
    "from pyspark.sql.types import StructType, StringType, ArrayType, TimestampType, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "This is the final capstone project for the Data Engineer Nano Degree. Udacity provides\n",
    "a topic of the final project with provided dataset, where students should show their gained \n",
    "through their learning path knowledge. Beside of provided topic for the capstone project, there is \n",
    "also a chance to choose your own dataset, but with some strict requirements:\n",
    ">- _Dataset should contain at least 1 Million rows_\n",
    ">- _Dataset should have at least two different data sources(JSON, CSV,...)_\n",
    "\n",
    "In my case I've decided to explore my own dataset :blush:, which I found in Kaggle, called\n",
    "  [The Movies Kaggle dataset.](https://www.kaggle.com/rounakbanik/the-movies-dataset?select=credits.csv)\n",
    "\n",
    "### Goal of this project  \n",
    "The goal of this project is to create an ETL process to extract,\n",
    "transform and load data from existing CSV/JSON files from S3 bucket to AWS Redshift Datawarehouse\n",
    "using Apache Airflow to automate as much as possible ETL process. Star Schema of tables in Redshift\n",
    "allows quick analysys of data by using simple queries without JOIN statements. Apache Airflow allows\n",
    "to schedule tasks and see the execution status of Pipeline steps. \n",
    "Data Warehouse has an ability to distribute data by key among CPU's which\n",
    "encreases query the Data. \n",
    "\n",
    "\n",
    "#### Movie Dataset\n",
    "This Dataset is taken from [The Movies Kaggle dataset.](https://www.kaggle.com/rounakbanik/the-movies-dataset?select=credits.csv)\n",
    "These files contain metadata for all 45,000 movies listed in the Full MovieLens Dataset. The dataset consists of movies released on or before July 2017. Data points include cast, crew, plot keywords, budget, revenue, posters, release dates, languages, production companies, countries, TMDB vote counts and vote averages.\n",
    "This dataset also has files containing 26 million ratings from 270,000 users for all 45,000 movies. Ratings are on a scale of 1-5 and have been obtained from the official GroupLens website.\n",
    "\n",
    "### Source Files and Data Structure\n",
    ">- movies_metadata.csv: \n",
    "> \n",
    "> The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, revenue, release dates, languages, production countries and companies.\n",
    "\n",
    ">- ratings.json\n",
    "> \n",
    "> contains information about: ratings of movies given by users in particular time.\n",
    "\n",
    ">- credits.csv\n",
    "> \n",
    "> Consists of Cast and Crew Information for all our movies. Available in the form of a stringified JSON Object.\n",
    "\n",
    ">- keywords.csv:\n",
    "> \n",
    "> Contains the movie plot keywords for our MovieLens movies. Available in the form of a stringified JSON Object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Step 1.1 Setting Access to the Source files and reading them to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Getting AWS credentials from config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "AWS_ACCESS_KEY_ID=config.get('default','AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY=config.get('default','AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "            .appName(\"my_app\") \\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "            .config(\"spark.sql.broadcastTimeout\", \"360000\")\\\n",
    "            .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Setting AWS credentials to spark \n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", AWS_ACCESS_KEY_ID)\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", AWS_SECRET_ACCESS_KEY)\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\",\"org.apache.hadoop.fs.s3a.BasicAWSCredentialsProvider\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Path does not exist: s3a://tempbucket1168/dim_movies.parquet;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o54.parquet.\n: org.apache.spark.sql.AnalysisException: Path does not exist: s3a://tempbucket1168/dim_movies.parquet;\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:558)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:641)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-539af5d26b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3a://tempbucket1168/dim_movies.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, *paths)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Path does not exist: s3a://tempbucket1168/dim_movies.parquet;'"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"s3a://tempbucket1168/dim_movies.parquet\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read data from source files to spark dataframes from S3 bucket\n",
    "\n",
    "movies_df = spark.read.format('csv').options(header='true', inferSchema='true', mode='PERMISSIVE').load(\"s3a://tempbucket1168/movies_metadata.csv\")\n",
    "keywords_df = spark.read.format('csv').options(header='true', inferSchema='true', mode='PERMISSIVE').load(\"s3a://tempbucket1168/keywords.csv\")\n",
    "credits_df = spark.read.format('csv').options(header='true', inferSchema='true', mode='PERMISSIVE').load(\"s3a://tempbucket1168/credits.csv\")\n",
    "ratings_df =spark.read.format('org.apache.spark.sql.json').load(\"s3a://tempbucket1168/ratings.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adult: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- cast: string (nullable = true)\n",
      " |-- crew: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Exploring dataframe schemas\n",
    "\n",
    "movies_df.printSchema()\n",
    "keywords_df.printSchema()\n",
    "credits_df.printSchema()\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(adult='False', belongs_to_collection=\"{'id': 10194, 'name': 'Toy Story Collection', 'poster_path': '/7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg', 'backdrop_path': '/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg'}\", budget='30000000', genres=\"[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]\", homepage='http://toystory.disney.com/toy-story', id='862', imdb_id='tt0114709', original_language='en', original_title='Toy Story', overview=\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\", popularity='21.946943', poster_path='/rhIRbceoE9lR4veEXuwCC2wARtG.jpg', production_companies=\"[{'name': 'Pixar Animation Studios', 'id': 3}]\", production_countries=\"[{'iso_3166_1': 'US', 'name': 'United States of America'}]\", release_date='1995-10-30', revenue='373554033', runtime='81.0', spoken_languages=\"[{'iso_639_1': 'en', 'name': 'English'}]\", status='Released', tagline=None, title='Toy Story', video='False', vote_average='7.7', vote_count='5415')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Exploring data structures of movies_df\n",
    "# For our data analysis Team we are interested in the following column extraction:\n",
    "# id, title, overview, release_date, original_language, runtime, vote_average, production_companies, vote_count, revenue, budget\n",
    "movies_df.head(1)\n",
    "\n",
    "#Following quality issues:\n",
    "# id->(Null values, not integer, duplicates);title->(Null values);overview->(Null values);release_date->(Null values, not date format);original_language->(Null values);\n",
    "# runtime->(Null values, not integer);vote_average->(Null values, not float);production_companies->(Null values, not array);vote_count->(Null values, not float);\n",
    "# revenue->(Null values, not float);budget->(Null values, not float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=862, keywords=\"[{'id': 931, 'name': 'jealousy'}, {'id': 4290, 'name': 'toy'}, {'id': 5202, 'name': 'boy'}, {'id': 6054, 'name': 'friendship'}, {'id': 9713, 'name': 'friends'}, {'id': 9823, 'name': 'rivalry'}, {'id': 165503, 'name': 'boy next door'}, {'id': 170722, 'name': 'new toy'}, {'id': 187065, 'name': 'toy comes to life'}]\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Exploring data structures of keywords_df\n",
    "# For our data analysis Team we are interested in the following column extraction:\n",
    "# id, keywords\n",
    "\n",
    "keywords_df.head(1)\n",
    "\n",
    "#Following quality issues:\n",
    "# id->(Null values, not integer, duplicates);keywords->(Null values, not array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cast=\"[{'cast_id': 14, 'character': 'Woody (voice)', 'credit_id': '52fe4284c3a36847f8024f95', 'gender': 2, 'id': 31, 'name': 'Tom Hanks', 'order': 0, 'profile_path': '/pQFoyx7rp09CJTAb932F2g8Nlho.jpg'}, {'cast_id': 15, 'character': 'Buzz Lightyear (voice)', 'credit_id': '52fe4284c3a36847f8024f99', 'gender': 2, 'id': 12898, 'name': 'Tim Allen', 'order': 1, 'profile_path': '/uX2xVf6pMmPepxnvFWyBtjexzgY.jpg'}, {'cast_id': 16, 'character': 'Mr. Potato Head (voice)', 'credit_id': '52fe4284c3a36847f8024f9d', 'gender': 2, 'id': 7167, 'name': 'Don Rickles', 'order': 2, 'profile_path': '/h5BcaDMPRVLHLDzbQavec4xfSdt.jpg'}, {'cast_id': 17, 'character': 'Slinky Dog (voice)', 'credit_id': '52fe4284c3a36847f8024fa1', 'gender': 2, 'id': 12899, 'name': 'Jim Varney', 'order': 3, 'profile_path': '/eIo2jVVXYgjDtaHoF19Ll9vtW7h.jpg'}, {'cast_id': 18, 'character': 'Rex (voice)', 'credit_id': '52fe4284c3a36847f8024fa5', 'gender': 2, 'id': 12900, 'name': 'Wallace Shawn', 'order': 4, 'profile_path': '/oGE6JqPP2xH4tNORKNqxbNPYi7u.jpg'}, {'cast_id': 19, 'character': 'Hamm (voice)', 'credit_id': '52fe4284c3a36847f8024fa9', 'gender': 2, 'id': 7907, 'name': 'John Ratzenberger', 'order': 5, 'profile_path': '/yGechiKWL6TJDfVE2KPSJYqdMsY.jpg'}, {'cast_id': 20, 'character': 'Bo Peep (voice)', 'credit_id': '52fe4284c3a36847f8024fad', 'gender': 1, 'id': 8873, 'name': 'Annie Potts', 'order': 6, 'profile_path': '/eryXT84RL41jHSJcMy4kS3u9y6w.jpg'}, {'cast_id': 26, 'character': 'Andy (voice)', 'credit_id': '52fe4284c3a36847f8024fc1', 'gender': 0, 'id': 1116442, 'name': 'John Morris', 'order': 7, 'profile_path': '/vYGyvK4LzeaUCoNSHtsuqJUY15M.jpg'}, {'cast_id': 22, 'character': 'Sid (voice)', 'credit_id': '52fe4284c3a36847f8024fb1', 'gender': 2, 'id': 12901, 'name': 'Erik von Detten', 'order': 8, 'profile_path': '/twnF1ZaJ1FUNUuo6xLXwcxjayBE.jpg'}, {'cast_id': 23, 'character': 'Mrs. Davis (voice)', 'credit_id': '52fe4284c3a36847f8024fb5', 'gender': 1, 'id': 12133, 'name': 'Laurie Metcalf', 'order': 9, 'profile_path': '/unMMIT60eoBM2sN2nyR7EZ2BvvD.jpg'}, {'cast_id': 24, 'character': 'Sergeant (voice)', 'credit_id': '52fe4284c3a36847f8024fb9', 'gender': 2, 'id': 8655, 'name': 'R. Lee Ermey', 'order': 10, 'profile_path': '/r8GBqFBjypLUP9VVqDqfZ7wYbSs.jpg'}, {'cast_id': 25, 'character': 'Hannah (voice)', 'credit_id': '52fe4284c3a36847f8024fbd', 'gender': 1, 'id': 12903, 'name': 'Sarah Freeman', 'order': 11, 'profile_path': None}, {'cast_id': 27, 'character': 'TV Announcer (voice)', 'credit_id': '52fe4284c3a36847f8024fc5', 'gender': 2, 'id': 37221, 'name': 'Penn Jillette', 'order': 12, 'profile_path': '/zmAaXUdx12NRsssgHbk1T31j2x9.jpg'}]\", crew='\"[{\\'credit_id\\': \\'52fe4284c3a36847f8024f49\\', \\'department\\': \\'Directing\\', \\'gender\\': 2, \\'id\\': 7879, \\'job\\': \\'Director\\', \\'name\\': \\'John Lasseter\\', \\'profile_path\\': \\'/7EdqiNbr4FRjIhKHyPPdFfEEEFG.jpg\\'}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f4f\\', \\'department\\': \\'Writing\\', \\'gender\\': 2, \\'id\\': 12891, \\'job\\': \\'Screenplay\\', \\'name\\': \\'Joss Whedon\\', \\'profile_path\\': \\'/dTiVsuaTVTeGmvkhcyJvKp2A5kr.jpg\\'}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f55\\', \\'department\\': \\'Writing\\', \\'gender\\': 2, \\'id\\': 7, \\'job\\': \\'Screenplay\\', \\'name\\': \\'Andrew Stanton\\', \\'profile_path\\': \\'/pvQWsu0qc8JFQhMVJkTHuexUAa1.jpg\\'}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f5b\\', \\'department\\': \\'Writing\\', \\'gender\\': 2, \\'id\\': 12892, \\'job\\': \\'Screenplay\\', \\'name\\': \\'Joel Cohen\\', \\'profile_path\\': \\'/dAubAiZcvKFbboWlj7oXOkZnTSu.jpg\\'}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f61\\', \\'department\\': \\'Writing\\', \\'gender\\': 0, \\'id\\': 12893, \\'job\\': \\'Screenplay\\', \\'name\\': \\'Alec Sokolow\\', \\'profile_path\\': \\'/v79vlRYi94BZUQnkkyznbGUZLjT.jpg\\'}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f67\\', \\'department\\': \\'Production\\', \\'gender\\': 1, \\'id\\': 12894, \\'job\\': \\'Producer\\', \\'name\\': \\'Bonnie Arnold\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f6d\\', \\'department\\': \\'Production\\', \\'gender\\': 0, \\'id\\': 12895, \\'job\\': \\'Executive Producer\\', \\'name\\': \\'Ed Catmull\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f73\\', \\'department\\': \\'Production\\', \\'gender\\': 2, \\'id\\': 12896, \\'job\\': \\'Producer\\', \\'name\\': \\'Ralph Guggenheim\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f79\\', \\'department\\': \\'Production\\', \\'gender\\': 2, \\'id\\': 12897, \\'job\\': \\'Executive Producer\\', \\'name\\': \\'Steve Jobs\\', \\'profile_path\\': \\'/mOMP3SwD5qWQSR0ldCIByd3guTV.jpg\\'}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f8b\\', \\'department\\': \\'Editing\\', \\'gender\\': 2, \\'id\\': 8, \\'job\\': \\'Editor\\', \\'name\\': \\'Lee Unkrich\\', \\'profile_path\\': \\'/bdTCCXjgOV3YyaNmLGYGOxFQMOc.jpg\\'}, {\\'credit_id\\': \\'52fe4284c3a36847f8024f91\\', \\'department\\': \\'Art\\', \\'gender\\': 2, \\'id\\': 7883, \\'job\\': \\'Art Direction\\', \\'name\\': \\'Ralph Eggleston\\', \\'profile_path\\': \\'/uUfcGKDsKO1aROMpXRs67Hn6RvR.jpg\\'}, {\\'credit_id\\': \\'598331bf925141421201044b\\', \\'department\\': \\'Editing\\', \\'gender\\': 2, \\'id\\': 1168870, \\'job\\': \\'Editor\\', \\'name\\': \\'Robert Gordon\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892168cc3a36809660095f9\\', \\'department\\': \\'Sound\\', \\'gender\\': 0, \\'id\\': 1552883, \\'job\\': \\'Foley Editor\\', \\'name\\': \\'Mary Helen Leasman\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5531824d9251415289000945\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1453514, \\'job\\': \\'Animation\\', \\'name\\': \\'Kim Blanchette\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589215969251412dcb009bf6\\', \\'department\\': \\'Sound\\', \\'gender\\': 0, \\'id\\': 1414182, \\'job\\': \\'ADR Editor\\', \\'name\\': \\'Marilyn McCoppen\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589217099251412dc500a018\\', \\'department\\': \\'Sound\\', \\'gender\\': 2, \\'id\\': 7885, \\'job\\': \\'Orchestrator\\', \\'name\\': \\'Randy Newman\\', \\'profile_path\\': \\'/w0JzfoiM25nrnxYOzosPHRq6mlE.jpg\\'}, {\\'credit_id\\': \\'5693e6b29251417b0e0000e3\\', \\'department\\': \\'Editing\\', \\'gender\\': 0, \\'id\\': 1429549, \\'job\\': \\'Color Timer\\', \\'name\\': \\'Dale E. Grahn\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'572e2522c3a36869e6001a9c\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 7949, \\'job\\': \\'CG Painter\\', \\'name\\': \\'Robin Cooper\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'574f12309251415ca1000012\\', \\'department\\': \\'Writing\\', \\'gender\\': 2, \\'id\\': 7879, \\'job\\': \\'Original Story\\', \\'name\\': \\'John Lasseter\\', \\'profile_path\\': \\'/7EdqiNbr4FRjIhKHyPPdFfEEEFG.jpg\\'}, {\\'credit_id\\': \\'574f1240c3a3682e7300001c\\', \\'department\\': \\'Writing\\', \\'gender\\': 2, \\'id\\': 12890, \\'job\\': \\'Original Story\\', \\'name\\': \\'Pete Docter\\', \\'profile_path\\': \\'/r6ngPgnReA3RHmKjmSoVsc6Awjp.jpg\\'}, {\\'credit_id\\': \\'574f12519251415c92000015\\', \\'department\\': \\'Writing\\', \\'gender\\': 0, \\'id\\': 7911, \\'job\\': \\'Original Story\\', \\'name\\': \\'Joe Ranft\\', \\'profile_path\\': \\'/f1BoWC2JbCcfP1e5hKfGsxkHzVU.jpg\\'}, {\\'credit_id\\': \\'574f12cec3a3682e82000022\\', \\'department\\': \\'Crew\\', \\'gender\\': 0, \\'id\\': 1629419, \\'job\\': \\'Post Production Supervisor\\', \\'name\\': \\'Patsy Bouge\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'574f14f19251415ca1000082\\', \\'department\\': \\'Art\\', \\'gender\\': 0, \\'id\\': 7961, \\'job\\': \\'Sculptor\\', \\'name\\': \\'Norm DeCarlo\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5751ae4bc3a3683772002b7f\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 2, \\'id\\': 12905, \\'job\\': \\'Animation Director\\', \\'name\\': \\'Ash Brannon\\', \\'profile_path\\': \\'/6ueWgPEEBHvS3De2BHYQnYjRTig.jpg\\'}, {\\'credit_id\\': \\'5891edbe9251412dc5007cd6\\', \\'department\\': \\'Sound\\', \\'gender\\': 2, \\'id\\': 7885, \\'job\\': \\'Music\\', \\'name\\': \\'Randy Newman\\', \\'profile_path\\': \\'/w0JzfoiM25nrnxYOzosPHRq6mlE.jpg\\'}, {\\'credit_id\\': \\'589213d39251412dc8009832\\', \\'department\\': \\'Directing\\', \\'gender\\': 0, \\'id\\': 1748707, \\'job\\': \\'Layout\\', \\'name\\': \\'Roman Figun\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892173dc3a3680968009351\\', \\'department\\': \\'Sound\\', \\'gender\\': 2, \\'id\\': 4949, \\'job\\': \\'Orchestrator\\', \\'name\\': \\'Don Davis\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589217cec3a3686b0a0052ba\\', \\'department\\': \\'Sound\\', \\'gender\\': 0, \\'id\\': 1372885, \\'job\\': \\'Music Editor\\', \\'name\\': \\'James Flamberg\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921831c3a3686348004a64\\', \\'department\\': \\'Editing\\', \\'gender\\': 0, \\'id\\': 1739962, \\'job\\': \\'Negative Cutter\\', \\'name\\': \\'Mary Beth Smith\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921838c3a36809700096c0\\', \\'department\\': \\'Editing\\', \\'gender\\': 0, \\'id\\': 1748513, \\'job\\': \\'Negative Cutter\\', \\'name\\': \\'Rick Mackay\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589218429251412dd1009d1b\\', \\'department\\': \\'Art\\', \\'gender\\': 0, \\'id\\': 1458006, \\'job\\': \\'Title Designer\\', \\'name\\': \\'Susan Bradley\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5891ed99c3a3680966007670\\', \\'department\\': \\'Crew\\', \\'gender\\': 0, \\'id\\': 1748557, \\'job\\': \\'Supervising Technical Director\\', \\'name\\': \\'William Reeves\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5891edcec3a3686b0a002eb2\\', \\'department\\': \\'Sound\\', \\'gender\\': 2, \\'id\\': 7885, \\'job\\': \\'Songs\\', \\'name\\': \\'Randy Newman\\', \\'profile_path\\': \\'/w0JzfoiM25nrnxYOzosPHRq6mlE.jpg\\'}, {\\'credit_id\\': \\'5891edf9c3a36809700075e6\\', \\'department\\': \\'Writing\\', \\'gender\\': 2, \\'id\\': 7, \\'job\\': \\'Original Story\\', \\'name\\': \\'Andrew Stanton\\', \\'profile_path\\': \\'/pvQWsu0qc8JFQhMVJkTHuexUAa1.jpg\\'}, {\\'credit_id\\': \\'58920f0b9251412dd7009104\\', \\'department\\': \\'Crew\\', \\'gender\\': 2, \\'id\\': 12890, \\'job\\': \\'Supervising Animator\\', \\'name\\': \\'Pete Docter\\', \\'profile_path\\': \\'/r6ngPgnReA3RHmKjmSoVsc6Awjp.jpg\\'}, {\\'credit_id\\': \\'58920f1fc3a3680977009021\\', \\'department\\': \\'Sound\\', \\'gender\\': 2, \\'id\\': 2216, \\'job\\': \\'Sound Designer\\', \\'name\\': \\'Gary Rydstrom\\', \\'profile_path\\': \\'/jZpr1nVfO7lldWI0YtmP1FGw7Rj.jpg\\'}, {\\'credit_id\\': \\'58920f389251412dd700912d\\', \\'department\\': \\'Production\\', \\'gender\\': 0, \\'id\\': 12909, \\'job\\': \\'Production Supervisor\\', \\'name\\': \\'Karen Robert Jackson\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58920fbd9251412dcb00969c\\', \\'department\\': \\'Crew\\', \\'gender\\': 0, \\'id\\': 953331, \\'job\\': \\'Executive Music Producer\\', \\'name\\': \\'Chris Montan\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589210069251412dd7009219\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 7893, \\'job\\': \\'Animation Director\\', \\'name\\': \\'Rich Quade\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589210329251412dcd00943b\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 8025, \\'job\\': \\'Animation\\', \\'name\\': \\'Michael Berenstein\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892103bc3a368096a009180\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 78009, \\'job\\': \\'Animation\\', \\'name\\': \\'Colin Brady\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892105dc3a3680968008db2\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748682, \\'job\\': \\'Animation\\', \\'name\\': \\'Davey Crockett Feiten\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589210669251412dcd009466\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1454030, \\'job\\': \\'Animation\\', \\'name\\': \\'Angie Glocka\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892107c9251412dd1009613\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748683, \\'job\\': \\'Animation\\', \\'name\\': \\'Rex Grignon\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892108ac3a3680973008d3f\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748684, \\'job\\': \\'Animation\\', \\'name\\': \\'Tom K. Gurney\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921093c3a3686348004477\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 2, \\'id\\': 8029, \\'job\\': \\'Animation\\', \\'name\\': \\'Jimmy Hayward\\', \\'profile_path\\': \\'/lTDRpudEY7BDwTefXbXzMlmb0ui.jpg\\'}, {\\'credit_id\\': \\'5892109b9251412dcd0094b0\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1426773, \\'job\\': \\'Animation\\', \\'name\\': \\'Hal T. Hickel\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589210a29251412dc5009a29\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 8035, \\'job\\': \\'Animation\\', \\'name\\': \\'Karen Kiser\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589210ccc3a3680977009191\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748688, \\'job\\': \\'Animation\\', \\'name\\': \\'Anthony B. LaMolinara\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589210d7c3a3686b0a004c1f\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 587314, \\'job\\': \\'Animation\\', \\'name\\': \\'Guionne Leroy\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589210e1c3a36809770091a7\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 2, \\'id\\': 7918, \\'job\\': \\'Animation\\', \\'name\\': \\'Bud Luckey\\', \\'profile_path\\': \\'/pcCh7G19FKMNijmPQg1PMH1btic.jpg\\'}, {\\'credit_id\\': \\'589210ee9251412dc200978a\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748689, \\'job\\': \\'Animation\\', \\'name\\': \\'Les Major\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589210fa9251412dc8009595\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 2, \\'id\\': 7892, \\'job\\': \\'Animation\\', \\'name\\': \\'Glenn McQueen\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589211029251412dc8009598\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 555795, \\'job\\': \\'Animation\\', \\'name\\': \\'Mark Oftedal\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892110b9251412dc800959d\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 2, \\'id\\': 7882, \\'job\\': \\'Animation\\', \\'name\\': \\'Jeff Pidgeon\\', \\'profile_path\\': \\'/yLddkg5HcgbJg00cS13GVBnP0HY.jpg\\'}, {\\'credit_id\\': \\'58921113c3a36863480044e4\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 8017, \\'job\\': \\'Animation\\', \\'name\\': \\'Jeff Pratt\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892111c9251412dcb0097e9\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1184140, \\'job\\': \\'Animation\\', \\'name\\': \\'Steve Rabatich\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921123c3a36809700090f6\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 8049, \\'job\\': \\'Animation\\', \\'name\\': \\'Roger Rose\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892112b9251412dcb0097fb\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1509559, \\'job\\': \\'Animation\\', \\'name\\': \\'Steve Segal\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589211349251412dc80095c3\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748691, \\'job\\': \\'Animation\\', \\'name\\': \\'Doug Sheppeck\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892113cc3a3680970009106\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 8050, \\'job\\': \\'Animation\\', \\'name\\': \\'Alan Sperling\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921148c3a3686b0a004c99\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 8010, \\'job\\': \\'Animation\\', \\'name\\': \\'Doug Sweetland\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921150c3a3680966009125\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 8044, \\'job\\': \\'Animation\\', \\'name\\': \\'David Tart\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589211629251412dc5009b00\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1454034, \\'job\\': \\'Animation\\', \\'name\\': \\'Ken Willard\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589211c1c3a3686b0a004d28\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 7887, \\'job\\': \\'Visual Effects Supervisor\\', \\'name\\': \\'Thomas Porter\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589211d4c3a3680968008ed9\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1406878, \\'job\\': \\'Visual Effects\\', \\'name\\': \\'Mark Thomas Henne\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589211f59251412dd4008e65\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748698, \\'job\\': \\'Visual Effects\\', \\'name\\': \\'Oren Jacob\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921242c3a368096a00939b\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748699, \\'job\\': \\'Visual Effects\\', \\'name\\': \\'Darwyn Peachey\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892124b9251412dc5009bd2\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748701, \\'job\\': \\'Visual Effects\\', \\'name\\': \\'Mitch Prater\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921264c3a3686b0a004dbf\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748703, \\'job\\': \\'Visual Effects\\', \\'name\\': \\'Brian M. Rosen\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589212709251412dcd009676\\', \\'department\\': \\'Lighting\\', \\'gender\\': 1, \\'id\\': 12912, \\'job\\': \\'Lighting Supervisor\\', \\'name\\': \\'Sharon Calahan\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892127fc3a3686b0a004de5\\', \\'department\\': \\'Lighting\\', \\'gender\\': 0, \\'id\\': 7899, \\'job\\': \\'Lighting Supervisor\\', \\'name\\': \\'Galyn Susman\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589212cdc3a3680970009268\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 12915, \\'job\\': \\'CG Painter\\', \\'name\\': \\'William Cone\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892130f9251412dc8009791\\', \\'department\\': \\'Art\\', \\'gender\\': 0, \\'id\\': 1748705, \\'job\\': \\'Sculptor\\', \\'name\\': \\'Shelley Daniels Lekven\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892131c9251412dd4008f4c\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 2, \\'id\\': 7889, \\'job\\': \\'Character Designer\\', \\'name\\': \\'Bob Pauley\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589213249251412dd100987b\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 2, \\'id\\': 7918, \\'job\\': \\'Character Designer\\', \\'name\\': \\'Bud Luckey\\', \\'profile_path\\': \\'/pcCh7G19FKMNijmPQg1PMH1btic.jpg\\'}, {\\'credit_id\\': \\'5892132b9251412dc80097b1\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 2, \\'id\\': 7, \\'job\\': \\'Character Designer\\', \\'name\\': \\'Andrew Stanton\\', \\'profile_path\\': \\'/pvQWsu0qc8JFQhMVJkTHuexUAa1.jpg\\'}, {\\'credit_id\\': \\'58921332c3a368634800467b\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 12915, \\'job\\': \\'Character Designer\\', \\'name\\': \\'William Cone\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892135f9251412dd4008f90\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1748706, \\'job\\': \\'Character Designer\\', \\'name\\': \\'Steve Johnson\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'58921384c3a3680973008fd4\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1176752, \\'job\\': \\'Character Designer\\', \\'name\\': \\'Dan Haskett\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'5892138e9251412dc20099fc\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1088034, \\'job\\': \\'Character Designer\\', \\'name\\': \\'Tom Holloway\\', \\'profile_path\\': \\'/a0r0T2usTBpgMI5aZbRBDW1fTl8.jpg\\'}, {\\'credit_id\\': \\'58921395c3a368097700942f\\', \\'department\\': \\'Visual Effects\\', \\'gender\\': 0, \\'id\\': 1447465, \\'job\\': \\'Character Designer\\', \\'name\\': \\'Jean Gillmore\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589213e2c3a3680973009026\\', \\'department\\': \\'Directing\\', \\'gender\\': 0, \\'id\\': 1748709, \\'job\\': \\'Layout\\', \\'name\\': \\'DesirÃ©e Mourad\\', \\'profile_path\\': None}, {\\'credit_id\\': \\'589214099251412dc5009d57\\', \\'department\\': \\'Art\\', \\'gender\\': 0, \\'id\\': 1748710, \\'job\\': \\'Set Dresser\\', \\'name\\': \"\"Kelly O\\'Connell\"\"', id=\" 'profile_path': None}\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Exploring data structures of credits_df\n",
    "# For our data analysis Team we are interested in the following column extraction:\n",
    "# cast, crew, id\n",
    "\n",
    "credits_df.head(1)\n",
    "\n",
    "#Following quality issues:\n",
    "# id->(Null values, not integer, duplicates);cast->(Null values, not array);crew->(Null values, not array)\n",
    "\n",
    "# cast and crew columns are Stringified JSON format which we will parce into following columns:\n",
    "# (character ,name, gender) -> for dim_staff table;   (job, department, name, gender) -> for dim_crew table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+------+\n",
      "|movieId|rating| timestamp|userId|\n",
      "+-------+------+----------+------+\n",
      "|movieId|rating| timestamp|userId|\n",
      "|    110|   1.0|1425941529|     1|\n",
      "+-------+------+----------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Exploring data structures of ratings_df\n",
    "# For our data analysis Team we are interested in the following column extraction:\n",
    "# cast, crew, id\n",
    "\n",
    "ratings_df.show(2)\n",
    "\n",
    "#Following quality issues:\n",
    "# movieId->(Null values, not integer, duplicates);rating->(Null values, not float);timestamp->(Null values, not timestamp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Filtering movies dataframe\n",
    "movies_df = movies_df.filter(col(\"id\").cast(\"int\").isNotNull())\n",
    "movies_df = movies_df.filter(col(\"production_companies\").startswith('['))\n",
    "#Filtering keywords dataframe\n",
    "keywords_df = keywords_df.filter(col(\"id\").cast(\"int\").isNotNull())\n",
    "keywords_df = keywords_df.filter(col(\"keywords\").startswith('[{'))\n",
    "\n",
    "#Leaving only usefull columns in movies df \n",
    "movies_df = movies_df.select(col(\"id\").alias(\"movie_key\"),col(\"title\"),col(\"overview\"),col(\"release_date\"),col(\"original_language\").alias(\"language\"),col(\"runtime\"),col(\"vote_average\"),col(\"production_companies\"),col(\"vote_count\"),col(\"revenue\"),col(\"budget\"))\n",
    "#Left joining movies df with keywords df and dropping id column \n",
    "full_movies_df = movies_df.join(keywords_df,movies_df.movie_key ==  keywords_df.id,\"left\")\n",
    "full_movies_df = full_movies_df.drop(full_movies_df.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_key: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- vote_count: double (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      " |-- budget: double (nullable = true)\n",
      " |-- keywords: string (nullable = true)\n",
      "\n",
      "+---------+--------------------+--------------------+------------+--------+-------+------------+--------------------+----------+------------+------+--------------------+\n",
      "|movie_key|               title|            overview|release_date|language|runtime|vote_average|production_companies|vote_count|     revenue|budget|            keywords|\n",
      "+---------+--------------------+--------------------+------------+--------+-------+------------+--------------------+----------+------------+------+--------------------+\n",
      "|      862|           Toy Story|Led by Woody, And...|  1995-10-30|      en|     81|         7.7|[{'name': 'Pixar ...|    5415.0|3.73554033E8| 3.0E7|[{'id': 931, 'nam...|\n",
      "|     8844|             Jumanji|When siblings Jud...|  1995-12-15|      en|    104|         6.9|[{'name': 'TriSta...|    2413.0|2.62797249E8| 6.5E7|                null|\n",
      "|    15602|    Grumpier Old Men|A family wedding ...|  1995-12-22|      en|    101|         6.5|[{'name': 'Warner...|      92.0|         0.0|   0.0|[{'id': 1495, 'na...|\n",
      "|    11862|Father of the Bri...|Just when George ...|  1995-02-10|      en|    106|         5.7|[{'name': 'Sandol...|     173.0| 7.6578911E7|   0.0|[{'id': 1009, 'na...|\n",
      "|      949|                Heat|Obsessive master ...|  1995-12-15|      en|    170|         7.7|[{'name': 'Regenc...|    1886.0|1.87436818E8| 6.0E7|[{'id': 642, 'nam...|\n",
      "+---------+--------------------+--------------------+------------+--------+-------+------------+--------------------+----------+------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_movies_df = full_movies_df.withColumn(\"movie_key\", full_movies_df[\"movie_key\"].cast(IntegerType()))\n",
    "full_movies_df = full_movies_df.withColumn(\"runtime\", full_movies_df[\"runtime\"].cast(IntegerType()))\n",
    "full_movies_df = full_movies_df.withColumn(\"vote_average\", full_movies_df[\"vote_average\"].cast(DoubleType()))\n",
    "full_movies_df = full_movies_df.withColumn(\"vote_count\", full_movies_df[\"vote_count\"].cast(DoubleType()))\n",
    "full_movies_df = full_movies_df.withColumn(\"revenue\", full_movies_df[\"revenue\"].cast(DoubleType()))\n",
    "full_movies_df = full_movies_df.withColumn(\"budget\", full_movies_df[\"budget\"].cast(DoubleType()))\n",
    "full_movies_df.printSchema()\n",
    "full_movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Writing full_movies_df to parquet file in S3\n",
    "\n",
    "full_movies_df.write.mode(\"overwrite\").parquet('s3a://tempbucket1168/stage_movies.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movie_key: string, title: string, overview: string, release_date: string, language: string, runtime: string, vote_average: string, production_companies: string, vote_count: string, revenue: string, budget: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop full_movies_df\n",
    "full_movies_df.unpersist()\n",
    "keywords_df.unpersist()\n",
    "movies_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------+------+\n",
      "|movie_id|           character|    actor_name|gender|\n",
      "+--------+--------------------+--------------+------+\n",
      "|   15602|         Max Goldman|Walter Matthau|     2|\n",
      "|   15602|      John Gustafson|   Jack Lemmon|     2|\n",
      "|   15602|     Ariel Gustafson|   Ann-Margret|     1|\n",
      "|   15602|Maria Sophia Cole...|  Sophia Loren|     1|\n",
      "|   15602|   Melanie Gustafson|  Daryl Hannah|     1|\n",
      "+--------+--------------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------------+----------+-------------------+------+\n",
      "|movie_id|         job|department|               name|gender|\n",
      "+--------+------------+----------+-------------------+------+\n",
      "|   16420|      Writer|   Writing|William Shakespeare|     2|\n",
      "|   16420|    Director| Directing|      Oliver Parker|     2|\n",
      "|   16420|  Adaptation|   Writing|      Oliver Parker|     2|\n",
      "|   31174|    Director| Directing|  Richard Loncraine|     2|\n",
      "|   31174|Theatre Play|   Writing|William Shakespeare|     2|\n",
      "+--------+------------+----------+-------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating and filtering movie_staff/movie_crew dataframes from  credits df\n",
    "# creating and filtering movie_staff_df\n",
    "movie_staff_df = credits_df.select(col(\"id\"),col(\"cast\")).filter(col(\"id\").cast(\"int\").isNotNull()).filter(col(\"cast\").startswith('[{'))\n",
    "movie_staff_df = movie_staff_df.select(col(\"id\"),explode(from_json(col(\"cast\"), ArrayType(StringType()))).alias(\"staff_info\"))\n",
    "movie_staff_df = movie_staff_df.select(col(\"id\").alias(\"movie_id\"),json_tuple(col(\"staff_info\"),\"character\",\"name\",\"gender\").alias(\"character\",\"actor_name\",\"gender\"))\n",
    "movie_staff_df.show(5)\n",
    "\n",
    "# creating and filtering movie_crew_df\n",
    "movie_crew_df = credits_df.select(col(\"id\"),col(\"crew\")).filter(col(\"id\").cast(\"int\").isNotNull()).filter(col(\"crew\").startswith('[{'))\n",
    "movie_crew_df = movie_crew_df.select(col(\"id\"),explode(from_json(col(\"crew\"), ArrayType(StringType()))).alias(\"crew_info\"))\n",
    "movie_crew_df = movie_crew_df.select(col(\"id\").alias(\"movie_id\"),json_tuple(col(\"crew_info\"),\"job\",\"department\",\"name\",\"gender\").alias(\"job\",\"department\",\"name\",\"gender\"))\n",
    "movie_crew_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "movie_staff_df = movie_staff_df.withColumn(\"movie_id\", movie_staff_df[\"movie_id\"].cast(IntegerType()))\n",
    "movie_crew_df = movie_crew_df.withColumn(\"movie_id\", movie_crew_df[\"movie_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- character: string (nullable = true)\n",
      " |-- actor_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_staff_df.printSchema()\n",
    "movie_crew_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Writing to parquet file\n",
    "movie_staff_df.write.mode(\"overwrite\").parquet('s3a://tempbucket1168/dim_movie_staff.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Writing to parquet file\n",
    "movie_crew_df.write.mode(\"overwrite\").parquet('s3a://tempbucket1168/dim_movie_crew.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- character: string (nullable = true)\n",
      " |-- actor_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"s3a://tempbucket1168/dim_movie_staff.parquet\").printSchema()\n",
    "spark.read.parquet(\"s3a://tempbucket1168/dim_movie_crew.parquet\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+\n",
      "|user_key|movieId|rating|\n",
      "+--------+-------+------+\n",
      "|       1|    110|   1.0|\n",
      "|       1|    147|   4.5|\n",
      "|       1|    858|   5.0|\n",
      "|       1|   1221|   5.0|\n",
      "|       1|   1246|   5.0|\n",
      "+--------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|           date_key|hour|day|week|month|year|weekday|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|1970-01-17 12:05:41|  12| 17|   3|    1|1970|      7|\n",
      "|1970-01-17 12:05:42|  12| 17|   3|    1|1970|      7|\n",
      "|1970-01-17 12:05:41|  12| 17|   3|    1|1970|      7|\n",
      "|1970-01-17 12:05:41|  12| 17|   3|    1|1970|      7|\n",
      "|1970-01-17 12:05:41|  12| 17|   3|    1|1970|      7|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating and filtering users/date dataframes from  ratings df\n",
    "#Filtering data\n",
    "ratings_df = ratings_df.select(col(\"userId\").alias(\"user_key\"),col(\"movieId\"),col(\"rating\"),col(\"timestamp\")).filter(col(\"userId\").cast(\"int\").isNotNull()).filter(col(\"movieId\").cast(\"int\").isNotNull()).filter(col(\"rating\").cast(\"float\").isNotNull())\n",
    "#Creating users_df/date_df -> converting timestamp to TimestampType\n",
    "users_df = ratings_df.select(col(\"user_key\"),col(\"movieId\"),col(\"rating\"))\n",
    "users_df.show(5)\n",
    "\n",
    "# create timestamp column from original timestamp column\n",
    "date_df = ratings_df.select(col(\"timestamp\"))\n",
    "date_df = date_df.withColumn(\"date_key\", from_unixtime((col(\"timestamp\")/1000),\"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "# extract columns to create dim_date table\n",
    "dim_date = date_df.selectExpr(\"date_key\",\"hour(date_key) as hour\",\"day(date_key) as day\",\"weekofyear(date_key) as week\",\"month(date_key) as month\", \"year(date_key) as year\",\"dayofweek(date_key) as weekday\")\n",
    "dim_date.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.withColumn(\"user_key\", ratings_df[\"user_key\"].cast(IntegerType()))\n",
    "ratings_df = ratings_df.withColumn(\"movieId\", ratings_df[\"movieId\"].cast(IntegerType()))\n",
    "ratings_df = ratings_df.withColumn(\"rating\", ratings_df[\"rating\"].cast(DoubleType()))\n",
    "ratings_df = ratings_df.withColumn(\"timestamp\", ratings_df[\"timestamp\"].cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_key: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ratings_df.write.mode(\"overwrite\").parquet('s3a://tempbucket1168/stage_ratings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_df = users_df.withColumn(\"user_key\", users_df[\"user_key\"].cast(IntegerType()))\n",
    "users_df = users_df.withColumn(\"movieId\", users_df[\"movieId\"].cast(IntegerType()))\n",
    "users_df = users_df.withColumn(\"rating\", users_df[\"rating\"].cast(DoubleType()))\n",
    "dim_date = dim_date.withColumn(\"date_key\", dim_date[\"date_key\"].cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_key: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- date_key: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.printSchema()\n",
    "dim_date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Writing to parquet file\n",
    "users_df.write.mode(\"overwrite\").parquet('s3a://tempbucket1168/dim_users.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Writing to parquet file\n",
    "dim_date.write.mode(\"overwrite\").parquet('s3a://tempbucket1168/dim_date.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_key: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- date_key: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"s3a://tempbucket1168/dim_users.parquet\").printSchema()\n",
    "spark.read.parquet(\"s3a://tempbucket1168/dim_date.parquet\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "### Amazon Redshift - ERD\n",
    "\n",
    ">  For Amazon Redshift Datawarehouse I have chosen Star Schema (see pic. below) of tables, which\n",
    "> allows quick analysys of data by using simple queries without JOIN statements.\n",
    "> ![Alt text](./ERD_Capstone.png?raw=true \"Title\")\n",
    "\n",
    "### Tables structure and datatypes\n",
    "\n",
    "> fact_movies - _contains PRIMARY keys of dimentional tables and budget/revenue metrics of each movie_\n",
    "> - fact_movie_key: INT PRIMARY KEY\n",
    "> - movie_key: INT FOREIGN KEY\n",
    "> - user_key: INT FOREIGN KEY\n",
    "> - date_key: TIMESTAMP FOREIGN KEY\n",
    "> - movie_staff_key: INT FOREIGN KEY\n",
    "> - movie_crew_key: INT FOREIGN KEY\n",
    "> - budget: FLOAT\n",
    "> - revenue: FLOAT\n",
    "\n",
    ">### dim_movie - _contains information of 45000 movies_\n",
    ">\n",
    "> - movie_key: INT PRIMARY KEY\n",
    "> - title: VARCHAR\n",
    "> - overview: VARCHAR\n",
    "> - release_date: TEXT\n",
    "> - language: VARCHAR\n",
    "> - runtime: INT\n",
    "> - vote_avg: FLOAT\n",
    "> - production_companies: TEXT\n",
    "> - vote_count: FLOAT\n",
    "> - keywords: TEXT\n",
    "\n",
    ">### dim_users - _contains information of 270000 users with 26000000 movie ratings_\n",
    ">\n",
    "> - user_key: INT PRIMARY KEY\n",
    "> - movieID: INT\n",
    "> - rating: FLOAT\n",
    "\n",
    ">### dim_date - _date time-table when ratings were given_\n",
    ">\n",
    "> - date_key: TIMESTAMP PRIMARY KEY\n",
    "> - hour: INT\n",
    "> - day: INT\n",
    "> - week: INT\n",
    "> - month: INT\n",
    "> - year: INT\n",
    "> -weekday: INT\n",
    "\n",
    ">### dim_movie_staff - _contains information of actors and roles, which they played in movies_\n",
    "> - movie_staff_key: INT PRIMARY KEY\n",
    "> - character: VARCHAR\n",
    "> - name: VARCHAR\n",
    "> - movie_id: INT\n",
    "> - gender: VARCHAR\n",
    "\n",
    ">### dim_movie_crew - _contains information of crew of each movie_\n",
    ">\n",
    "> - movie_crew_key: INT PRIMARY KEY\n",
    "> - job: VARCHAR\n",
    "> - department: VARCHAR\n",
    "> - movie_id: INT\n",
    "> - name: VARCHAR\n",
    "> - gender: VARCHAR\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "1. COPY data to staging/dim tables in AWS Redshift\n",
    "2. INSERT data from staging tables to fact/dim tables\n",
    "3. RUN data quality check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
